
from fastapi import FastAPI, UploadFile, File, Body, Request
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
import shutil
import os
import base64
import tempfile
import pandas as pd
from MixedModelDOE_Function_OutputToWeb_InputExtended_20250815 import run_mixed_model_doe_with_output

app = FastAPI(
    title="Mixed Model DOE Analysis API",
    description="API for performing Design of Experiments (DOE) analysis using Mixed Models. Analyzes L*a*b color space data with statistical modeling.",
    version="1.1.0"
)

# æ·»åŠ  CORS ä¸­é—´ä»¶è§£å†³è·¨åŸŸé—®é¢˜
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰åŸŸåï¼Œç”Ÿäº§çŽ¯å¢ƒå»ºè®®æŒ‡å®šå…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰HTTPæ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´
)

# æ–°å¢žï¼šå¸¦åŽç«¯æ ¡éªŒçš„ DOE_InputExtended æŽ¥å£
def validate_column_names(col_list):
    import re
    for col in col_list:
        if not re.match(r'^[\w\s]+$', col):
            return False, col
    return True, None

@app.post("/DOE_InputExtended")
async def doe_input_extended(request: Request):
    data = await request.json()
    predictors = data.get("predictors", [])
    response_vars = data.get("response_vars", [])
    # åŽç«¯æ ¡éªŒ
    for col_list in [predictors, response_vars]:
        valid, invalid_col = validate_column_names(col_list)
        if not valid:
            return JSONResponse(
                status_code=400,
                content={"status": "error", "message": f"Invalid column name: {invalid_col}"}
            )
    # å…¶å®ƒå‚æ•°
    file_path = data.get("file_path")
    output_dir = data.get("output_dir", "./outputDOE")
    # è°ƒç”¨åˆ†æžä¸»å‡½æ•°
    try:
        console_output = run_mixed_model_doe_with_output(
            file_path=file_path,
            output_dir=output_dir,
            predictors=predictors,
            response_vars=response_vars
        )
        return {
            "status": "success",
            "input_file": file_path,
            "output_dir": output_dir,
            "console_output": console_output
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": f"DOE analysis failed: {str(e)}"}
        )

# æ ¹è·¯å¾„æä¾› HTML ç•Œé¢
@app.get("/")
async def serve_html():
    """
    æä¾›ä¸» HTML ç•Œé¢
    """
    return FileResponse("MixedModelDOE_Web_V1.html")

@app.post("/runDOE")
async def run_doe(file: UploadFile = File(None)):
    # å¤„ç†æœªä¸Šä¼ æ–‡ä»¶æˆ–ç©ºæ–‡ä»¶åçš„æƒ…å†µï¼Œè¿”å›žæ ‡å‡† JSON é”™è¯¯
    if file is None or not hasattr(file, "filename") or not file.filename:
        return JSONResponse(
            status_code=400,
            content={"status": "error", "message": "No file uploaded"}
        )

    # ä½¿ç”¨ os.path.basename æ¸…ç†ä¸Šä¼ æ–‡ä»¶åï¼Œé˜²æ­¢è·¯å¾„ç©¿è¶Šæ”»å‡»
    safe_filename = os.path.basename(file.filename)

    # è®¾ç½®è¾“å…¥å’Œè¾“å‡ºç›®å½•ï¼ˆé€‚ç”¨äºŽ Windowsï¼‰
    input_dir = "./input"
    output_dir = "./outputDOE"
    os.makedirs(input_dir, exist_ok=True)
    os.makedirs(output_dir, exist_ok=True)

    # æž„å»ºå®‰å…¨çš„è¾“å…¥æ–‡ä»¶è·¯å¾„
    input_path = os.path.join(input_dir, safe_filename)

    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    try:
        with open(input_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": f"File save failed: {str(e)}"}
        )

    # è°ƒç”¨ DOE å‡½æ•°
    try:
        console_output = run_mixed_model_doe_with_output(file_path=input_path, output_dir=output_dir)
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": f"DOE analysis failed: {str(e)}"}
        )

    # è¿”å›žç»“æžœ
    return {
        "status": "success",
        "input_file": input_path,
        "output_dir": output_dir,
        "files": os.listdir(output_dir),
        "console_output": console_output  # ðŸ†• æ·»åŠ æŽ§åˆ¶å°è¾“å‡º
    }

@app.get("/runDOE")
async def run_doe_get():
    return {"status": "ready"}


# ðŸ†• æ–°å¢žï¼šä¸‹è½½ç”Ÿæˆçš„æ–‡ä»¶
@app.get("/download/{filename}")
async def download_file(filename: str):
    """
    ä¸‹è½½åˆ†æžç”Ÿæˆçš„æ–‡ä»¶
    ä¾‹å¦‚ï¼š/download/simplified_logworth.csv
    """
    output_dir = "./outputDOE"
    file_path = os.path.join(output_dir, filename)
    
    if not os.path.exists(file_path):
        return JSONResponse(
            status_code=404,
            content={"status": "error", "message": f"File {filename} not found"}
        )
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='application/octet-stream'
    )

# ðŸ†• æ–°å¢žï¼šåˆ—å‡ºæ‰€æœ‰å¯ä¸‹è½½çš„æ–‡ä»¶
@app.get("/files")
async def list_files():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ä¸‹è½½çš„åˆ†æžç»“æžœæ–‡ä»¶
    """
    output_dir = "./outputDOE"
    if not os.path.exists(output_dir):
        return {"files": [], "message": "No analysis results available. Run DOE analysis first."}
    
    files = [f for f in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, f))]
    return {
        "files": files,
        "download_urls": [f"/download/{f}" for f in files],
        "total_files": len(files)
    }


# æ–°å¢žï¼šæ”¯æŒ JSON body ä¼  base64 ç¼–ç çš„ CSV å†…å®¹
from pydantic import BaseModel
from typing import Optional, List

class DOEJsonRequest(BaseModel):
    filename: str
    file_b64: str  # base64 encoded CSV content

# æ–°å¢žï¼šAI Foundry å…¼å®¹çš„ DOE åˆ†æžè¯·æ±‚æ ¼å¼
class DoeAnalysisRequest(BaseModel):
    data: str  # base64 encoded CSV data or URL or raw CSV
    response_column: str  # comma-separated string like "Lvalue,Avalue,Bvalue"
    predictors: Optional[str] = None  # comma-separated string, optional
    threshold: Optional[float] = 1.5
    force_full_dataset: Optional[bool] = True

@app.post("/runDOEjson")
async def run_doe_json(request: DOEJsonRequest):
    try:
        # è§£ç  base64 å†…å®¹å¹¶ä¿å­˜ä¸ºä¸´æ—¶ CSV æ–‡ä»¶
        csv_bytes = base64.b64decode(request.file_b64)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp:
            tmp.write(csv_bytes)
            tmp_path = tmp.name
        # è®¾ç½®è¾“å‡ºç›®å½•
        output_dir = "./outputDOE"
        os.makedirs(output_dir, exist_ok=True)
        # è°ƒç”¨ DOE åˆ†æž
        console_output = run_mixed_model_doe_with_output(file_path=tmp_path, output_dir=output_dir)
        # è¿”å›žç»“æžœ
        return {
            "status": "success",
            "input_file": tmp_path,
            "output_dir": output_dir,
            "files": os.listdir(output_dir),
            "console_output": console_output  # ðŸ†• æ·»åŠ æŽ§åˆ¶å°è¾“å‡º
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": f"DOE analysis failed: {str(e)}"}
        )


# æ–°å¢žï¼šAI Foundry å…¼å®¹çš„ DOE åˆ†æžæŽ¥å£
@app.post("/api/DoeAnalysis")
async def doe_analysis(request: DoeAnalysisRequest):
    """
    AI Foundry compatible DOE Analysis endpoint.
    Supports flexible data input and configurable response variables.
    """
    try:
        # å¤„ç†æ•°æ®è¾“å…¥ - æ”¯æŒ base64, URL æˆ–åŽŸå§‹ CSV
        if request.data.startswith("http"):
            # URL è¾“å…¥ - æš‚æ—¶ä¸æ”¯æŒï¼Œè¿”å›žé”™è¯¯
            return JSONResponse(
                status_code=400,
                content={"status": "error", "message": "URL data input not supported yet. Please use base64 encoded data."}
            )
        elif "," in request.data and "\n" in request.data:
            # åŽŸå§‹ CSV æ•°æ®
            csv_content = request.data.encode('utf-8')
        else:
            # base64 ç¼–ç æ•°æ®
            try:
                csv_content = base64.b64decode(request.data)
            except Exception:
                return JSONResponse(
                    status_code=400,
                    content={"status": "error", "message": "Invalid base64 data format"}
                )
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=".csv", mode='wb') as tmp:
            tmp.write(csv_content)
            tmp_path = tmp.name
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        output_dir = "./outputDOE"
        os.makedirs(output_dir, exist_ok=True)
        
        # è°ƒç”¨ DOE åˆ†æž
        console_output = run_mixed_model_doe_with_output(file_path=tmp_path, output_dir=output_dir)
        
        # æž„å»ºå“åº”æ ¼å¼ï¼Œå…¼å®¹ AI Foundry
        response = {
            "status": "success",
            "summary": {
                "response_variables": request.response_column.split(","),
                "threshold": request.threshold,
                "force_full_dataset": request.force_full_dataset,
                "analysis_completed": True
            },
            "input_file": tmp_path,
            "output_dir": output_dir,
            "files": os.listdir(output_dir),
            "console_output": console_output  # ðŸ†• æ·»åŠ æŽ§åˆ¶å°è¾“å‡º
        }
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(tmp_path)
        except:
            pass
            
        return response
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": f"DOE analysis failed: {str(e)}"}
        )


# ===== Copilot Agent é›†æˆ API =====

# ç®€å•çš„å†…å­˜å­˜å‚¨ï¼ˆç”Ÿäº§çŽ¯å¢ƒå»ºè®®ä½¿ç”¨æ•°æ®åº“ï¼‰
analysis_storage = {}

@app.post("/store_analysis")
async def store_analysis(request: dict):
    """
    å­˜å‚¨ DOE åˆ†æžç»“æžœï¼Œä¾› Copilot Agent ç¨åŽè°ƒç”¨
    """
    try:
        analysis_id = request.get("analysis_id")
        console_output = request.get("console_output")
        timestamp = request.get("timestamp")
        metadata = request.get("metadata", {})
        
        if not analysis_id or not console_output:
            return JSONResponse(
                status_code=400,
                content={"status": "error", "message": "Missing analysis_id or console_output"}
            )
        
        # èŽ·å–å½“å‰å¯ç”¨æ–‡ä»¶åˆ—è¡¨
        output_dir = "./outputDOE"
        available_files = []
        if os.path.exists(output_dir):
            available_files = os.listdir(output_dir)
        
        # å­˜å‚¨åˆ†æžæ•°æ®
        analysis_storage[analysis_id] = {
            "console_output": console_output,
            "timestamp": timestamp,
            "metadata": metadata,
            "files": available_files,
            "download_base_url": "https://function-togithub-thentowebdirectly.onrender.com/download/"
        }
        
        return {
            "status": "success", 
            "stored_id": analysis_id,
            "files_count": len(available_files)
        }
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": f"Failed to store analysis: {str(e)}"}
        )


@app.get("/get_analysis_for_copilot")
async def get_analysis_for_copilot(analysis_id: str = None):
    """
    ä¸“é—¨ç»™ Copilot Agent è°ƒç”¨çš„æŽ¥å£
    è¿”å›žæŒ‡å®šåˆ†æžçš„ç»“æžœï¼Œæ ¼å¼åŒ–ä¸ºé€‚åˆ AI è§£æžçš„æ–‡æœ¬
    """
    if not analysis_id:
        return JSONResponse(
            status_code=400,
            content={"status": "error", "message": "Missing analysis_id parameter"}
        )
    
    if analysis_id not in analysis_storage:
        return JSONResponse(
            status_code=404,
            content={"status": "error", "message": f"Analysis {analysis_id} not found"}
        )
    
    try:
        analysis_data = analysis_storage[analysis_id]
        
        # æ ¼å¼åŒ–ä¸ºé€‚åˆ AI åˆ†æžçš„ç»“æž„
        formatted_response = {
            "status": "success",
            "analysis_id": analysis_id,
            "analysis_text": analysis_data["console_output"],
            "summary": extract_key_metrics(analysis_data["console_output"]),
            "timestamp": analysis_data["timestamp"],
            "files_available": analysis_data["files"],
            "download_base_url": analysis_data["download_base_url"],
            "ai_prompt_suggestion": generate_ai_prompt_suggestion(analysis_data["console_output"])
        }
        
        return formatted_response
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": f"Failed to retrieve analysis: {str(e)}"}
        )


def extract_key_metrics(console_output: str) -> dict:
    """
    ä»ŽæŽ§åˆ¶å°è¾“å‡ºä¸­æå–å…³é”®æŒ‡æ ‡
    """
    try:
        summary = {
            "model_found": "Mixed Model" in console_output,
            "logworth_analysis": "LogWorth" in console_output,
            "r_squared": None,
            "significant_effects": []
        }
        
        # ç®€å•çš„å…³é”®è¯æå–
        lines = console_output.split('\n')
        for line in lines:
            if "R-squared" in line or "RÂ²" in line:
                # å°è¯•æå– R-squared å€¼
                import re
                r_match = re.search(r'(\d+\.\d+)', line)
                if r_match:
                    summary["r_squared"] = float(r_match.group(1))
        
        return summary
        
    except Exception:
        return {"extraction_error": "Failed to parse console output"}


def generate_ai_prompt_suggestion(console_output: str) -> str:
    """
    ä¸º AI ç”Ÿæˆåˆ†æžæç¤ºå»ºè®®
    """
    return f"""è¿™æ˜¯ä¸€ä¸ª DOE (Design of Experiments) æ··åˆæ¨¡åž‹åˆ†æžç»“æžœã€‚è¯·å¸®æˆ‘åˆ†æžä»¥ä¸‹å†…å®¹ï¼š

1. ðŸ“Š æ¨¡åž‹æ‹Ÿåˆè´¨é‡å¦‚ä½•ï¼Ÿ
2. ðŸ” å“ªäº›å› å­å…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Ÿ
3. ðŸ“ˆ LogWorth å€¼çš„è§£è¯»å’ŒæŽ’åº
4. ðŸ’¡ åŸºäºŽç»“æžœçš„å·¥è‰ºä¼˜åŒ–å»ºè®®
5. âš ï¸ æ˜¯å¦æœ‰éœ€è¦å…³æ³¨çš„å¼‚å¸¸æˆ–è­¦å‘Šï¼Ÿ

åˆ†æžç»“æžœï¼š
{console_output[:2000]}{'...(å†…å®¹æˆªæ–­)' if len(console_output) > 2000 else ''}"""
